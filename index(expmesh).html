<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Expression & Recognition System</title>
    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
    <style>
        body, html {
            margin: 0;
            padding: 0;
            font-family: Arial, sans-serif;
            background-color: #f0f0f0;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 15px;
        }
        
        h1 {
            text-align: center;
            margin-bottom: 25px;
            color: #2c3e50;
        }
        
        .status-panel {
            background-color: rgba(255, 255, 255, 0.9);
            padding: 15px;
            border-radius: 10px;
            margin-bottom: 20px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .main-content {
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
        }
        
        .video-section {
            flex: 2;
            min-width: 300px;
        }
        
        .controls-section {
            flex: 1;
            min-width: 300px;
            background: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .video-container {
            position: relative;
            width: 100%;
            max-width: 640px;
            aspect-ratio: 4/3;
            margin: 0 auto;
            border: 2px solid #ced4da;
            border-radius: 10px;
            overflow: hidden;
            background-color: #000;
        }
        
        #video, #canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        
        #video {
            transform: scaleX(-1);
        }
        
        .overlay {
            position: absolute;
            top: 10px;
            left: 10px;
            background-color: rgba(0, 0, 0, 0.8);
            color: white;
            padding: 10px;
            border-radius: 5px;
            font-size: 14px;
            z-index: 1000;
            max-width: 250px;
        }
        
        .status-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 10px;
            margin-bottom: 20px;
        }
        
        .status-item {
            background: #f8f9fa;
            padding: 10px;
            border-radius: 5px;
            border-left: 4px solid #007bff;
        }
        
        .status-item.success {
            border-left-color: #28a745;
        }
        
        .status-item.warning {
            border-left-color: #ffc107;
        }
        
        .status-item.error {
            border-left-color: #dc3545;
        }
        
        .registration {
            margin-bottom: 20px;
        }
        
        .registration h3 {
            color: #2c3e50;
            margin-bottom: 15px;
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
        }
        
        input[type="text"], input[type="file"] {
            width: 100%;
            padding: 10px;
            margin: 5px 0;
            border: 1px solid #ced4da;
            border-radius: 5px;
            box-sizing: border-box;
        }
        
        button {
            width: 100%;
            padding: 10px;
            margin: 5px 0;
            border: none;
            border-radius: 5px;
            background: #007bff;
            color: white;
            cursor: pointer;
            font-size: 14px;
        }
        
        button:hover {
            background: #0056b3;
        }
        
        button:disabled {
            background: #6c757d;
            cursor: not-allowed;
        }
        
        .snap-btn {
            background: #28a745;
        }
        
        .snap-btn:hover {
            background: #218838;
        }
        
        .registered-faces {
            margin-top: 20px;
        }
        
        .face-item {
            display: flex;
            align-items: center;
            padding: 10px;
            margin: 5px 0;
            background: #f8f9fa;
            border-radius: 5px;
            border: 1px solid #ddd;
        }
        
        .face-item img {
            width: 50px;
            height: 50px;
            border-radius: 50%;
            margin-right: 10px;
            object-fit: cover;
        }
        
        .face-item span {
            flex: 1;
        }
        
        .face-item button {
            width: auto;
            padding: 5px 10px;
            background: #dc3545;
            font-size: 12px;
        }
        
        @media (max-width: 768px) {
            .main-content {
                flex-direction: column;
            }
            .status-grid {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Combined Face Expression & Recognition System üì∏</h1>
        
        <div class="status-panel">
            <div class="status-grid">
                <div class="status-item" id="modelStatus">
                    <strong>Models:</strong> Loading...
                </div>
                <div class="status-item" id="cameraStatus">
                    <strong>Camera:</strong> Initializing...
                </div>
                <div class="status-item" id="expressionStatus">
                    <strong>Expression:</strong> --
                </div>
                <div class="status-item" id="recognitionStatus">
                    <strong>Recognition:</strong> --
                </div>
            </div>
        </div>
        
        <div class="main-content">
            <div class="video-section">
                <div class="video-container">
                    <video id="video" autoplay playsinline muted></video>
                    <canvas id="canvas"></canvas>
                    <div class="overlay" id="overlay">
                        <div>System Status: Initializing...</div>
                        <div>Expression: --</div>
                        <div>Recognition: --</div>
                    </div>
                </div>
            </div>
            
            <div class="controls-section">
                <div class="registration">
                    <h3>Register New Face</h3>
                    <input type="text" id="personName" placeholder="Enter person's name">
                    <input type="file" id="imageUpload" accept="image/*">
                    <button id="registerBtn" disabled onclick="registerFromFile()">Register from File</button>
                    <button id="snapBtn" class="snap-btn" disabled onclick="snapAndRegister()">Snap & Register</button>
                </div>
                
                <div class="registered-faces">
                    <h3>Registered Faces</h3>
                    <div id="facesList"></div>
                </div>
            </div>
        </div>
    </div>

    <script>
        // Global variables
        let knownFaces = [];
        let modelsLoaded = false;
        let videoStreamActive = false;
        let faceMesh = null;
        let faceMatcher = null;
        let detectionInterval = null;
        let currentRecognitionResult = 'Initializing...';

        // DOM elements
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const overlay = document.getElementById('overlay');
        const modelStatusEl = document.getElementById('modelStatus');
        const cameraStatusEl = document.getElementById('cameraStatus');
        const expressionStatusEl = document.getElementById('expressionStatus');
        const recognitionStatusEl = document.getElementById('recognitionStatus');
        const registerBtn = document.getElementById('registerBtn');
        const snapBtn = document.getElementById('snapBtn');
        const personNameInput = document.getElementById('personName');
        const imageUploadInput = document.getElementById('imageUpload');
        const facesListEl = document.getElementById('facesList');
        
        // Initialize system
        async function initializeSystem() {
            try {
                modelStatusEl.innerHTML = '<strong>Models:</strong> Loading face-api.js...';
                await faceapi.nets.ssdMobilenetv1.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models');
                await faceapi.nets.faceLandmark68Net.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models');
                await faceapi.nets.faceRecognitionNet.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models');
                
                modelStatusEl.innerHTML = '<strong>Models:</strong> Loading MediaPipe...';
                faceMesh = new FaceMesh({
                    locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
                });
                
                faceMesh.setOptions({
                    maxNumFaces: 1,
                    minDetectionConfidence: 0.5,
                    minTrackingConfidence: 0.5
                });
                
                faceMesh.onResults(onFaceMeshResults);
                
                modelStatusEl.innerHTML = '<strong>Models:</strong> ‚úÖ Loaded';
                modelStatusEl.className = 'status-item success';
                modelsLoaded = true;
                
                await loadSavedFaces();
                await initializeCamera();
                updateButtonStates();
                
            } catch (error) {
                console.error('Initialization error:', error);
                modelStatusEl.innerHTML = '<strong>Models:</strong> ‚ùå Error loading';
                modelStatusEl.className = 'status-item error';
            }
        }

        async function initializeCamera() {
            try {
                cameraStatusEl.innerHTML = '<strong>Camera:</strong> Requesting access...';
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { facingMode: 'user' }, 
                    audio: false 
                });
                video.srcObject = stream;

                video.onloadedmetadata = () => {
                    video.play();
                    videoStreamActive = true;
                    cameraStatusEl.innerHTML = '<strong>Camera:</strong> ‚úÖ Active';
                    cameraStatusEl.className = 'status-item success';
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    updateButtonStates();
                    startDetection();
                };

            } catch (error) {
                console.error('Camera error:', error);
                cameraStatusEl.innerHTML = '<strong>Camera:</strong> ‚ùå Access denied';
                cameraStatusEl.className = 'status-item error';
                videoStreamActive = false;
            }
        }

        function onFaceMeshResults(results) {
            const canvasCtx = canvas.getContext('2d');
            canvasCtx.clearRect(0, 0, canvas.width, canvas.height);
            canvasCtx.save();
            canvasCtx.translate(canvas.width, 0);
            canvasCtx.scale(-1, 1);

            if (results.multiFaceLandmarks?.length) {
                const landmarks = results.multiFaceLandmarks[0];
                drawConnectors(canvasCtx, landmarks, FACEMESH_TESSELATION, 
                             {color: '#00FF0030', lineWidth: 1});
                const expression = detectExpression(landmarks);
                expressionStatusEl.innerHTML = `<strong>Expression:</strong> ${expression}`;
                expressionStatusEl.className = 'status-item success';
                updateOverlay('Face detected', expression, currentRecognitionResult);
            } else {
                expressionStatusEl.innerHTML = '<strong>Expression:</strong> No face';
                expressionStatusEl.className = 'status-item warning';
                currentRecognitionResult = 'No face detected';
                updateOverlay('No face detected', '--', currentRecognitionResult);
            }
            canvasCtx.restore();
        }

        function detectExpression(landmarks) {
            const mouthWidth = Math.abs(landmarks[291].x - landmarks[61].x);
            const mouthHeight = Math.abs(landmarks[14].y - landmarks[13].y);
            if (mouthWidth > 0.05 && mouthHeight > 0.02) return "üòä Smile";
            if (mouthHeight < 0.01) return "üòê Neutral";
            return "‚òπÔ∏è Frown";
        }

        function startDetection() {
            if (!modelsLoaded || !videoStreamActive) return;

            const camera = new Camera(video, {
                onFrame: async () => faceMesh && await faceMesh.send({image: video}),
                width: video.videoWidth,
                height: video.videoHeight
            });
            camera.start();

            if (detectionInterval) clearInterval(detectionInterval);
            detectionInterval = setInterval(async () => {
                try {
                    const detections = await faceapi.detectAllFaces(video, 
                        new faceapi.SsdMobilenetv1Options({ minConfidence: 0.5 }))
                        .withFaceLandmarks()
                        .withFaceDescriptors();

                    if (!detections?.length) {
                        currentRecognitionResult = 'No face detected';
                        recognitionStatusEl.innerHTML = '<strong>Recognition:</strong> No face';
                        recognitionStatusEl.className = 'status-item warning';
                        return;
                    }

                    if (!faceMatcher) {
                        currentRecognitionResult = 'No registered faces';
                        recognitionStatusEl.innerHTML = '<strong>Recognition:</strong> No registered faces';
                        recognitionStatusEl.className = 'status-item warning';
                        return;
                    }

                    const bestMatch = faceMatcher.findBestMatch(detections[0].descriptor);
                    if (bestMatch.label === 'unknown') {
                        currentRecognitionResult = 'Unknown person';
                        recognitionStatusEl.innerHTML = '<strong>Recognition:</strong> Unknown person';
                        recognitionStatusEl.className = 'status-item warning';
                    } else {
                        currentRecognitionResult = `${bestMatch.label} (${bestMatch.distance.toFixed(2)})`;
                        recognitionStatusEl.innerHTML = `<strong>Recognition:</strong> ${currentRecognitionResult}`;
                        recognitionStatusEl.className = 'status-item success';
                    }
                } catch (error) {
                    console.error('Recognition error:', error);
                    currentRecognitionResult = 'Recognition error';
                    recognitionStatusEl.className = 'status-item error';
                }
            }, 500);
        }

        async function processAndRegisterFace(base64Image, name) {
            try {
                const img = await createImageFromBase64(base64Image);
                const detection = await faceapi.detectSingleFace(img)
                    .withFaceLandmarks()
                    .withFaceDescriptor();

                if (!detection) {
                    alert('No face detected in image');
                    return;
                }

                const newFace = {
                    id: `${name}_${Date.now()}`,
                    name: name,
                    descriptor: Array.from(detection.descriptor),
                    image: base64Image
                };

                knownFaces.push(newFace);
                localStorage.setItem('knownFaces', JSON.stringify(knownFaces));

                const labeledDescriptors = knownFaces.map(face => 
                    new faceapi.LabeledFaceDescriptors(face.name, [new Float32Array(face.descriptor)])
                );
                faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, 0.55);
                displayRegisteredFaces();
                alert(`${name} registered successfully!`);

            } catch (error) {
                console.error('Registration error:', error);
                alert(`Registration failed: ${error.message}`);
            }
        }

        function displayRegisteredFaces() {
            facesListEl.innerHTML = knownFaces.length ? '' : '<p>No registered faces</p>';
            knownFaces.forEach(face => {
                const div = document.createElement('div');
                div.className = 'face-item';
                div.innerHTML = `
                    <img src="${face.image}" alt="${face.name}">
                    <span>${face.name}</span>
                    <button onclick="deleteFace('${face.id}')">Delete</button>
                `;
                facesListEl.appendChild(div);
            });
        }

        function deleteFace(id) {
            if (!confirm('Delete this face?')) return;
            knownFaces = knownFaces.filter(f => f.id !== id);
            localStorage.setItem('knownFaces', JSON.stringify(knownFaces));
            
            if (knownFaces.length) {
                const labeledDescriptors = knownFaces.map(face => 
                    new faceapi.LabeledFaceDescriptors(face.name, [new Float32Array(face.descriptor)])
                );
                faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, 0.55);
            } else {
                faceMatcher = null;
            }
            displayRegisteredFaces();
        }

        // Utility functions
        const convertFileToBase64 = file => new Promise((resolve, reject) => {
            const reader = new FileReader();
            reader.onload = () => resolve(reader.result);
            reader.onerror = reject;
            reader.readAsDataURL(file);
        });

        const createImageFromBase64 = base64 => new Promise((resolve, reject) => {
            const img = new Image();
            img.onload = () => resolve(img);
            img.onerror = reject;
            img.src = base64;
        });

        const updateOverlay = (status, expression, recognition) => {
            overlay.innerHTML = `
                <div>Status: ${status}</div>
                <div>Expression: ${expression}</div>
                <div>Recognition: ${recognition}</div>
            `;
        };

        const updateButtonStates = () => {
            registerBtn.disabled = !modelsLoaded;
            snapBtn.disabled = !(modelsLoaded && videoStreamActive);
        };

        // Event listeners
        window.addEventListener('DOMContentLoaded', initializeSystem);
        window.addEventListener('beforeunload', () => {
            video.srcObject?.getTracks().forEach(track => track.stop());
            clearInterval(detectionInterval);
        });

        // Expose functions to HTML buttons
        window.registerFromFile = async () => {
            const file = imageUploadInput.files[0];
            const name = personNameInput.value.trim();
            if (!file || !name) return alert('Please provide both name and image');
            await processAndRegisterFace(await convertFileToBase64(file), name);
            imageUploadInput.value = '';
            personNameInput.value = '';
        };

        window.snapAndRegister = async () => {
            const name = personNameInput.value.trim();
            if (!name) return alert('Please enter a name');
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvas.getContext('2d').drawImage(video, 0, 0);
            await processAndRegisterFace(canvas.toDataURL('image/jpeg'), name);
            personNameInput.value = '';
        };
    </script>
</body>
</html>
