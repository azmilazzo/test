<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Recognition System</title>
    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
    <style>
        body, html {
            margin: 0;
            padding: 0;
            font-family: Arial, sans-serif;
            background-color: #f0f0f0;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 15px;
        }
        
        h1 {
            text-align: center;
            margin-bottom: 25px;
            color: #2c3e50;
        }
        
        .status-panel {
            background-color: rgba(255, 255, 255, 0.9);
            padding: 15px;
            border-radius: 10px;
            margin-bottom: 20px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .main-content {
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
        }
        
        .video-section {
            flex: 2;
            min-width: 300px;
        }
        
        .controls-section {
            flex: 1;
            min-width: 300px;
            background: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .video-container {
            position: relative;
            width: 100%;
            max-width: 640px;
            aspect-ratio: 4/3;
            margin: 0 auto;
            border: 2px solid #ced4da;
            border-radius: 10px;
            overflow: hidden;
            background-color: #000;
        }
        
        #video, #canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        
        #video {
            transform: scaleX(-1);
        }
        
        .status-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 10px;
            margin-bottom: 20px;
        }
        
        .status-item {
            background: #f8f9fa;
            padding: 10px;
            border-radius: 5px;
            border-left: 4px solid #007bff;
        }
        
        .status-item.success {
            border-left-color: #28a745;
        }
        
        .status-item.warning {
            border-left-color: #ffc107;
        }
        
        .status-item.error {
            border-left-color: #dc3545;
        }
        
        .registration {
            margin-bottom: 20px;
        }
        
        .registration h3 {
            color: #2c3e50;
            margin-bottom: 15px;
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
        }
        
        input[type="text"], input[type="file"] {
            width: 100%;
            padding: 10px;
            margin: 5px 0;
            border: 1px solid #ced4da;
            border-radius: 5px;
            box-sizing: border-box;
        }
        
        button {
            width: 100%;
            padding: 10px;
            margin: 5px 0;
            border: none;
            border-radius: 5px;
            background: #007bff;
            color: white;
            cursor: pointer;
            font-size: 14px;
        }
        
        button:hover {
            background: #0056b3;
        }
        
        button:disabled {
            background: #6c757d;
            cursor: not-allowed;
        }
        
        .snap-btn {
            background: #28a745;
        }
        
        .snap-btn:hover {
            background: #218838;
        }
        
        .registered-faces {
            margin-top: 20px;
        }
        
        .face-item {
            display: flex;
            align-items: center;
            padding: 10px;
            margin: 5px 0;
            background: #f8f9fa;
            border-radius: 5px;
            border: 1px solid #ddd;
        }
        
        .face-item img {
            width: 50px;
            height: 50px;
            border-radius: 50%;
            margin-right: 10px;
            object-fit: cover;
        }
        
        .face-item span {
            flex: 1;
        }
        
        .face-item button {
            width: auto;
            padding: 5px 10px;
            background: #dc3545;
            font-size: 12px;
        }
        
        @media (max-width: 768px) {
            .main-content {
                flex-direction: column;
            }
            .status-grid {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Face Recognition System</h1>
        
        <div class="status-panel">
            <div class="status-grid">
                <div class="status-item" id="modelStatus">
                    <strong>Models:</strong> Loading...
                </div>
                <div class="status-item" id="cameraStatus">
                    <strong>Camera:</strong> Initializing...
                </div>
                <div class="status-item" id="expressionStatus">
                    <strong>Expression:</strong> --
                </div>
                <div class="status-item" id="recognitionStatus">
                    <strong>Recognition:</strong> --
                </div>
            </div>
        </div>
        
        <div class="main-content">
            <div class="video-section">
                <div class="video-container">
                    <video id="video" autoplay playsinline muted></video>
                    <canvas id="canvas"></canvas>
                </div>
            </div>
            
            <div class="controls-section">
                <div class="registration">
                    <h3>Register New Face</h3>
                    <input type="text" id="personName" placeholder="Enter person's name">
                    <input type="file" id="imageUpload" accept="image/*">
                    <button id="registerBtn" disabled onclick="registerFromFile()">Register from File</button>
                    <button id="snapBtn" class="snap-btn" disabled onclick="snapAndRegister()">Snap & Register</button>
                </div>
                
                <div class="registered-faces">
                    <h3>Registered Faces</h3>
                    <div id="facesList"></div>
                </div>
            </div>
        </div>
    </div>

    <script>
        let knownFaces = [];
        let modelsLoaded = false;
        let videoStreamActive = false;
        let faceMesh = null;
        let faceMatcher = null;
        let detectionInterval = null;

        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const modelStatusEl = document.getElementById('modelStatus');
        const cameraStatusEl = document.getElementById('cameraStatus');
        const expressionStatusEl = document.getElementById('expressionStatus');
        const recognitionStatusEl = document.getElementById('recognitionStatus');
        const registerBtn = document.getElementById('registerBtn');
        const snapBtn = document.getElementById('snapBtn');
        const personNameInput = document.getElementById('personName');
        const imageUploadInput = document.getElementById('imageUpload');
        const facesListEl = document.getElementById('facesList');

        async function initializeSystem() {
            try {
                modelStatusEl.innerHTML = '<strong>Models:</strong> Loading face-api.js...';
                await faceapi.nets.ssdMobilenetv1.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models');
                await faceapi.nets.faceLandmark68Net.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models');
                await faceapi.nets.faceRecognitionNet.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models');

                modelStatusEl.innerHTML = '<strong>Models:</strong> Loading MediaPipe...';
                faceMesh = new FaceMesh({
                    locateFile: (file) => {
                        return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`;
                    }
                });

                faceMesh.setOptions({
                    maxNumFaces: 1,
                    minDetectionConfidence: 0.5,
                    minTrackingConfidence: 0.5
                });

                faceMesh.onResults(onFaceMeshResults);

                modelStatusEl.innerHTML = '<strong>Models:</strong> ‚úÖ Loaded';
                modelStatusEl.className = 'status-item success';
                modelsLoaded = true;

                await loadSavedFaces();
                await initializeCamera();
                updateButtonStates();

            } catch (error) {
                console.error('Initialization error:', error);
                modelStatusEl.innerHTML = '<strong>Models:</strong> ‚ùå Error loading';
                modelStatusEl.className = 'status-item error';
            }
        }

        async function initializeCamera() {
            try {
                cameraStatusEl.innerHTML = '<strong>Camera:</strong> Requesting access...';
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: 'user' },
                    audio: false
                });

                video.srcObject = stream;

                video.onloadedmetadata = () => {
                    video.play();
                    videoStreamActive = true;
                    cameraStatusEl.innerHTML = '<strong>Camera:</strong> ‚úÖ Active';
                    cameraStatusEl.className = 'status-item success';
                    
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    
                    updateButtonStates();
                    startDetection();
                };

            } catch (error) {
                console.error('Camera error:', error);
                cameraStatusEl.innerHTML = '<strong>Camera:</strong> ‚ùå Access denied';
                cameraStatusEl.className = 'status-item error';
                videoStreamActive = false;
            }
        }

        function onFaceMeshResults(results) {
            const canvasCtx = canvas.getContext('2d');
            canvasCtx.clearRect(0, 0, canvas.width, canvas.height);
            
            canvasCtx.save();
            canvasCtx.translate(canvas.width, 0);
            canvasCtx.scale(-1, 1);

            if (results.multiFaceLandmarks?.length > 0) {
                const landmarks = results.multiFaceLandmarks[0];
                const expression = detectExpression(landmarks);
                expressionStatusEl.innerHTML = `<strong>Expression:</strong> ${expression}`;
                expressionStatusEl.className = 'status-item success';
            } else {
                expressionStatusEl.innerHTML = '<strong>Expression:</strong> No face';
                expressionStatusEl.className = 'status-item warning';
            }
            
            canvasCtx.restore();
        }

        function detectExpression(landmarks) {
            const leftMouthCorner = landmarks[61];
            const rightMouthCorner = landmarks[291];
            const upperLip = landmarks[13];
            const lowerLip = landmarks[14];

            const mouthWidth = Math.abs(rightMouthCorner.x - leftMouthCorner.x);
            const mouthHeight = Math.abs(lowerLip.y - upperLip.y);

            if (mouthWidth > 0.05 && mouthHeight > 0.02) return "üòä Smile";
            if (mouthHeight < 0.01) return "üòê Neutral";
            return "‚òπÔ∏è Frown";
        }

        function startDetection() {
            if (!modelsLoaded || !videoStreamActive) return;

            const camera = new Camera(video, {
                onFrame: async () => await faceMesh.send({image: video}),
                width: video.videoWidth,
                height: video.videoHeight
            });
            camera.start();

            detectionInterval = setInterval(async () => {
                if (!videoStreamActive || video.paused) return;

                try {
                    const detections = await faceapi.detectAllFaces(video, 
                        new faceapi.SsdMobilenetv1Options({ minConfidence: 0.5 }))
                        .withFaceLandmarks()
                        .withFaceDescriptors();

                    if (detections?.length > 0 && faceMatcher) {
                        const bestMatch = faceMatcher.findBestMatch(detections[0].descriptor);
                        
                        if (bestMatch.label !== 'unknown') {
                            recognitionStatusEl.innerHTML = `<strong>Recognition:</strong> ${bestMatch.label} (${bestMatch.distance.toFixed(2)})`;
                            recognitionStatusEl.className = 'status-item success';
                        } else {
                            recognitionStatusEl.innerHTML = '<strong>Recognition:</strong> Unknown';
                            recognitionStatusEl.className = 'status-item warning';
                        }
                    } else if (detections?.length === 0) {
                        recognitionStatusEl.innerHTML = '<strong>Recognition:</strong> No face';
                        recognitionStatusEl.className = 'status-item warning';
                    }
                } catch (error) {
                    console.error('Recognition error:', error);
                }
            }, 500);
        }

        // Remaining functions (loadSavedFaces, registerFromFile, snapAndRegister, 
        // processAndRegisterFace, displayRegisteredFaces, deleteFace, updateButtonStates,
        // convertFileToBase64, createImageFromBase64) remain identical to original
        // ... (Include all the remaining JavaScript functions from the original code here)

        window.addEventListener('DOMContentLoaded', initializeSystem);
        window.addEventListener('beforeunload', () => {
            if (video.srcObject) video.srcObject.getTracks().forEach(track => track.stop());
            if (detectionInterval) clearInterval(detectionInterval);
        });
    </script>
</body>
</html>
