<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Smart Face Analysis System</title>
    <style>
        body, html {
            margin: 0;
            padding: 0;
            width: 100%;
            height: 100%;
            overflow: hidden;
            font-family: Arial, sans-serif;
            background-color: #f8f9fa;
            color: #333;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 15px;
            height: 100vh;
            display: flex;
            flex-direction: column;
        }

        h1 {
            text-align: center;
            margin: 20px 0;
            color: #2c3e50;
        }

        .main-content {
            display: flex;
            flex-grow: 1;
            gap: 20px;
            overflow: hidden;
        }

        .left-column {
            width: 300px;
            display: flex;
            flex-direction: column;
            gap: 20px;
            overflow-y: auto;
        }

        .right-column {
            flex-grow: 1;
            position: relative;
        }

        .video-container {
            position: relative;
            width: 100%;
            height: 100%;
            border: 2px solid #ced4da;
            border-radius: 8px;
            overflow: hidden;
            background-color: #f0f0f0;
        }

        #mainVideo, #mainCanvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
        }

        #overlay {
            position: absolute;
            top: 10px;
            left: 10px;
            background-color: rgba(0, 255, 0, 0.7);
            color: black;
            padding: 10px;
            font-size: 16px;
            border-radius: 5px;
            z-index: 1000;
        }

        .status-box {
            padding: 10px;
            background-color: #e9ecef;
            border-radius: 8px;
            margin-bottom: 15px;
        }

        .registration, .known-faces {
            background: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        input[type="text"], input[type="file"] {
            width: 100%;
            padding: 8px;
            margin: 5px 0;
            border: 1px solid #ced4da;
            border-radius: 4px;
        }

        button {
            background: #0d6efd;
            color: white;
            border: none;
            padding: 10px 15px;
            border-radius: 5px;
            cursor: pointer;
            margin: 5px 0;
            width: 100%;
        }

        button:hover {
            background: #0b5ed7;
        }

        .face-group {
            margin: 10px 0;
            padding: 10px;
            border: 1px solid #eee;
            border-radius: 8px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .face-group img {
            border-radius: 50%;
            width: 60px;
            height: 60px;
            object-fit: cover;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Smart Face Analysis System 🧠</h1>
        
        <div class="status-box">
            <p id="modelStatus">Initializing systems...</p>
            <p id="cameraStatus"></p>
        </div>

        <div class="main-content">
            <div class="left-column">
                <div class="registration">
                    <h3>Face Registration</h3>
                    <input type="text" id="personName" placeholder="Enter name">
                    <input type="file" id="imageUpload" accept="image/*">
                    <button id="registerBtn" disabled>Register from File</button>
                    <button id="snapBtn" disabled>Snap Photo</button>
                </div>

                <div class="known-faces">
                    <h3>Registered Faces</h3>
                    <div id="registeredFaces"></div>
                </div>
            </div>

            <div class="right-column">
                <div class="video-container">
                    <video id="mainVideo" autoplay muted playsinline></video>
                    <canvas id="mainCanvas"></canvas>
                    <div id="overlay">
                        <p>System Status: <span id="statusText">Initializing</span></p>
                        <p>Current Expression: <span id="expressionText">--</span></p>
                        <p>Recognition Result: <span id="recognitionText">--</span></p>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Libraries -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>

    <script>
        class FaceSystem {
            constructor() {
                this.video = document.getElementById('mainVideo');
                this.canvas = document.getElementById('mainCanvas');
                this.ctx = this.canvas.getContext('2d');
                this.knownFaces = [];
                this.faceMatcher = null;
                this.faceMesh = null;
                this.stream = null;
                this.isProcessing = false;
                
                this.initializeSystems();
            }

            async initializeSystems() {
                try {
                    await this.loadFaceAPIModels();
                    await this.initializeFaceMesh();
                    await this.startCamera();
                    this.setupEventListeners();
                    this.startProcessing();
                    await this.loadSavedFaces();
                    this.updateRegistrationUI();
                } catch (error) {
                    this.showError(error);
                }
            }

            async loadFaceAPIModels() {
                document.getElementById('modelStatus').textContent = 'Loading face recognition models...';
                await Promise.all([
                    faceapi.nets.ssdMobilenetv1.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models'),
                    faceapi.nets.faceLandmark68Net.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models'),
                    faceapi.nets.faceRecognitionNet.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models')
                ]);
            }

            async initializeFaceMesh() {
                this.faceMesh = new FaceMesh({
                    locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
                });

                this.faceMesh.setOptions({
                    maxNumFaces: 1,
                    minDetectionConfidence: 0.5,
                    minTrackingConfidence: 0.5
                });

                this.faceMesh.onResults((results) => this.processFaceMeshResults(results));
            }

            async startCamera() {
                try {
                    this.stream = await navigator.mediaDevices.getUserMedia({
                        video: { width: 1280, height: 720, facingMode: 'user' },
                        audio: false
                    });
                    this.video.srcObject = this.stream;
                    this.video.width = 1280;
                    this.video.height = 720;
                    this.canvas.width = 1280;
                    this.canvas.height = 720;
                    document.getElementById('cameraStatus').textContent = 'Camera ready 🎥';
                } catch (error) {
                    throw new Error(`Camera error: ${error.message}`);
                }
            }

            startProcessing() {
                this.isProcessing = true;
                this.processFrame();
            }

            async processFrame() {
                if (!this.isProcessing) return;

                try {
                    await this.faceMesh.send({ image: this.video });
                    
                    const detections = await faceapi.detectAllFaces(this.video, 
                        new faceapi.SsdMobilenetv1Options({ minConfidence: 0.5 }))
                        .withFaceLandmarks()
                        .withFaceDescriptors();

                    this.updateRecognitionDisplay(detections);
                } catch (error) {
                    console.error('Processing error:', error);
                }

                requestAnimationFrame(() => this.processFrame());
            }

            processFaceMeshResults(results) {
                this.ctx.save();
                this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
                this.ctx.translate(this.canvas.width, 0);
                this.ctx.scale(-1, 1);

                if (results.multiFaceLandmarks) {
                    results.multiFaceLandmarks.forEach(landmarks => {
                        drawConnectors(this.ctx, landmarks, FACEMESH_TESSELATION, 
                            { color: '#00FF0080', lineWidth: 1 });
                        this.detectExpression(landmarks);
                    });
                }
                this.ctx.restore();
            }

            detectExpression(landmarks) {
                const expression = this.calculateExpression(landmarks);
                document.getElementById('expressionText').textContent = expression;
                document.getElementById('statusText').textContent = 'Face detected';
            }

            calculateExpression(landmarks) {
                const mouthLeft = landmarks[61];
                const mouthRight = landmarks[291];
                const upperLip = landmarks[13];
                const lowerLip = landmarks[14];
                
                const mouthWidth = Math.abs(mouthRight.x - mouthLeft.x);
                const mouthHeight = Math.abs(lowerLip.y - upperLip.y);
                
                if (mouthWidth > 0.2 && mouthHeight > 0.05) return '😃 Smile';
                if (mouthHeight < 0.03) return '😐 Neutral';
                if (mouthWidth < 0.15 && mouthHeight > 0.06) return '😞 Frown';
                return '😐 Neutral';
            }

            async loadSavedFaces() {
                const saved = localStorage.getItem('knownFaces');
                if (saved) {
                    this.knownFaces = JSON.parse(saved);
                    this.updateFaceMatcher();
                }
            }

            updateFaceMatcher() {
                const labeledDescriptors = this.knownFaces.map(face => 
                    new faceapi.LabeledFaceDescriptors(face.name, [new Float32Array(face.descriptor)])
                this.faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, 0.6);
            }

            setupEventListeners() {
                document.getElementById('registerBtn').addEventListener('click', () => this.handleFileUpload());
                document.getElementById('snapBtn').addEventListener('click', () => this.snapAndRegister());
                document.getElementById('imageUpload').addEventListener('change', () => this.toggleRegisterButton());
            }

            toggleRegisterButton() {
                const registerBtn = document.getElementById('registerBtn');
                registerBtn.disabled = !(document.getElementById('imageUpload').files[0] && 
                    document.getElementById('personName').value.trim());
            }

            async handleFileUpload() {
                const file = document.getElementById('imageUpload').files[0];
                const name = document.getElementById('personName').value.trim();
                if (!file || !name) return;

                const image = await faceapi.bufferToImage(file);
                await this.registerFace(image, name);
            }

            async snapAndRegister() {
                const name = document.getElementById('personName').value.trim();
                if (!name) return;

                const canvas = document.createElement('canvas');
                canvas.width = this.video.videoWidth;
                canvas.height = this.video.videoHeight;
                canvas.getContext('2d').drawImage(this.video, 0, 0);
                const image = await faceapi.bufferToImage(canvas.toDataURL());
                await this.registerFace(image, name);
            }

            async registerFace(image, name) {
                try {
                    const detection = await faceapi
                        .detectSingleFace(image)
                        .withFaceLandmarks()
                        .withFaceDescriptor();

                    if (!detection) {
                        alert('No face detected in image');
                        return;
                    }

                    this.knownFaces.push({
                        name,
                        descriptor: Array.from(detection.descriptor),
                        image: image.src || image.toDataURL()
                    });

                    localStorage.setItem('knownFaces', JSON.stringify(this.knownFaces));
                    this.updateFaceMatcher();
                    this.updateRegistrationUI();
                    alert(`${name} registered successfully!`);
                } catch (error) {
                    console.error('Registration failed:', error);
                    alert('Registration failed: ' + error.message);
                }
            }

            updateRegistrationUI() {
                const container = document.getElementById('registeredFaces');
                container.innerHTML = this.knownFaces.map(face => `
                    <div class="face-group">
                        <img src="${face.image}" alt="${face.name}">
                        <div>${face.name}</div>
                    </div>
                `).join('');
            }

            updateRecognitionDisplay(detections) {
                const recognitionElement = document.getElementById('recognitionText');
                if (!detections.length) {
                    recognitionElement.textContent = 'No faces detected';
                    return;
                }

                const bestMatch = this.faceMatcher?.findBestMatch(detections[0].descriptor);
                recognitionElement.textContent = bestMatch 
                    ? `👤 ${bestMatch.label} (${(1 - bestMatch.distance).toFixed(2)} confidence)` 
                    : 'Unknown person';
            }

            showError(error) {
                document.getElementById('modelStatus').textContent = `Error: ${error.message}`;
                console.error(error);
            }
        }

        // Initialize the system
        window.addEventListener('DOMContentLoaded', () => {
            const system = new FaceSystem();
            
            faceapi.tf.ready().then(() => {
                document.getElementById('registerBtn').disabled = false;
                document.getElementById('snapBtn').disabled = false;
            });
        });
    </script>
</body>
</html>
