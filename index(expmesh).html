<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Smart Face System</title>
    <style>
        body, html {
            margin: 0;
            padding: 0;
            width: 100%;
            height: 100%;
            overflow: hidden;
            font-family: Arial, sans-serif;
            background-color: #f8f9fa;
            color: #333;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 15px;
            height: 100vh;
            display: flex;
            flex-direction: column;
        }

        h1 {
            text-align: center;
            margin-bottom: 25px;
            color: #2c3e50;
        }

        .main-content {
            display: flex;
            flex-grow: 1;
            gap: 20px;
            overflow: hidden;
        }

        .left-column {
            width: 300px;
            display: flex;
            flex-direction: column;
            gap: 20px;
            overflow-y: auto;
        }

        .right-column {
            flex-grow: 1;
            position: relative;
        }

        .video-container {
            position: relative;
            width: 100%;
            height: 100%;
            border: 2px solid #ced4da;
            border-radius: 8px;
            overflow: hidden;
            background-color: #f0f0f0;
        }

        #video, #canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
            transform: scaleX(-1);
        }

        #overlay {
            position: absolute;
            top: 10px;
            left: 10px;
            background-color: rgba(0, 255, 0, 0.7);
            color: black;
            padding: 10px;
            font-size: 16px;
            border-radius: 5px;
            z-index: 1000;
        }

        .status-box {
            padding: 10px;
            background-color: #e9ecef;
            border-radius: 8px;
            margin-bottom: 15px;
        }

        .registration, .known-faces {
            background: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        input[type="text"], input[type="file"] {
            width: 100%;
            padding: 8px;
            margin: 5px 0;
            border: 1px solid #ced4da;
            border-radius: 4px;
        }

        button {
            background: #0d6efd;
            color: white;
            border: none;
            padding: 10px 15px;
            border-radius: 5px;
            cursor: pointer;
            margin: 5px 0;
        }

        button:hover {
            background: #0b5ed7;
        }

        .face-group {
            margin: 10px 0;
            padding: 10px;
            border: 1px solid #eee;
            border-radius: 8px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Smart Face System ðŸ§ </h1>
        
        <div class="status-box">
            <p id="modelStatus">Loading models...</p>
            <p id="cameraStatus"></p>
        </div>

        <div class="main-content">
            <div class="left-column">
                <div class="registration">
                    <h3>Register Faces</h3>
                    <input type="text" id="personName" placeholder="Enter name">
                    <input type="file" id="imageUpload" accept="image/*">
                    <button id="registerBtn" disabled>Register from File</button>
                    <button id="snapBtn" disabled>Snap Photo</button>
                </div>

                <div class="known-faces">
                    <h3>Registered Faces</h3>
                    <div id="registeredFaces"></div>
                </div>
            </div>

            <div class="right-column">
                <div class="video-container">
                    <video id="video" autoplay muted playsinline></video>
                    <canvas id="canvas"></canvas>
                    <div id="overlay">
                        <p>Status: <span id="statusText">Initializing</span></p>
                        <p>Expression: <span id="expressionText">--</span></p>
                        <p>Recognition: <span id="recognitionText">--</span></p>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- MediaPipe Libraries -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
    
    <!-- Face API -->
    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>

    <script>
        // Common Elements
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const modelStatus = document.getElementById('modelStatus');
        const cameraStatus = document.getElementById('cameraStatus');
        const overlay = document.getElementById('overlay');

        // Face Recognition Variables
        let knownFaces = [];
        let faceMatcher;
        let detectionInterval;

        // Face Mesh Variables
        let faceMesh;

        async function initializeSystems() {
            try {
                // Load Face API models
                modelStatus.textContent = 'Loading face recognition models...';
                await faceapi.nets.ssdMobilenetv1.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models');
                await faceapi.nets.faceLandmark68Net.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models');
                await faceapi.nets.faceRecognitionNet.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models');

                // Initialize MediaPipe Face Mesh
                faceMesh = new FaceMesh({
                    locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
                });

                faceMesh.setOptions({
                    maxNumFaces: 1,
                    minDetectionConfidence: 0.5,
                    minTrackingConfidence: 0.5
                });

                faceMesh.onResults(processFaceMeshResults);

                // Start camera
                await initializeCamera();
                modelStatus.textContent = 'All models loaded! âœ…';
                
                // Start processing
                startFaceRecognition();
                startFaceMeshProcessing();

            } catch (error) {
                modelStatus.textContent = `Error: ${error.message}`;
            }
        }

        async function initializeCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { width: 1280, height: 720, facingMode: 'user' },
                    audio: false 
                });
                video.srcObject = stream;
                cameraStatus.textContent = 'Camera ready ðŸŽ¥';
            } catch (error) {
                cameraStatus.textContent = `Camera error: ${error.message}`;
            }
        }

        function startFaceMeshProcessing() {
            const sendToFaceMesh = () => {
                if (!video.paused && !video.ended) {
                    faceMesh.send({ image: video });
                }
                requestAnimationFrame(sendToFaceMesh);
            };
            sendToFaceMesh();
        }

        function processFaceMeshResults(results) {
            const ctx = canvas.getContext('2d');
            ctx.save();
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.translate(canvas.width, 0);
            ctx.scale(-1, 1);

            if (results.multiFaceLandmarks) {
                results.multiFaceLandmarks.forEach(landmarks => {
                    drawConnectors(ctx, landmarks, FACEMESH_TESSELATION, {color: '#00FF0080', lineWidth: 1});
                    const expression = detectExpression(landmarks);
                    document.getElementById('expressionText').textContent = expression;
                    document.getElementById('statusText').textContent = 'Face detected';
                });
            } else {
                document.getElementById('statusText').textContent = 'No face detected';
                document.getElementById('expressionText').textContent = '--';
            }
            ctx.restore();
        }

        function detectExpression(landmarks) {
            // Add your expression detection logic here
            return 'Neutral';
        }

        async function startFaceRecognition() {
            // Add face recognition logic here
        }

        window.addEventListener('DOMContentLoaded', initializeSystems);
    </script>
</body>
</html>
