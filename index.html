<!DOCTYPE html>
<html>
<head>
    <title>Local Face Recognition System</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #f8f9fa;
            color: #333;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 15px;
        }
        
        h1 {
            text-align: center;
            margin-bottom: 25px;
            color: #2c3e50;
        }

        .status, .camera-status {
            text-align: center;
            margin-bottom: 15px;
            padding: 10px;
            background-color: #e9ecef;
            border-radius: 8px;
            font-size: 0.9em;
        }
        
        #retryCameraBtn {
            background-color: #007bff;
            color: white;
            padding: 8px 15px;
        }
        
        #retryCameraBtn:hover {
            background-color: #0056b3;
        }
        
        .main-content {
            display: flex;
            flex-direction: row;
            flex-wrap: wrap; /* Allow columns to wrap */
            gap: 20px;
        }

        .left-column, .right-column {
            flex: 1;
            min-width: 300px; /* Minimum width before stacking */
            background: #fff;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        
        .registration, .known-faces, .recognition {
            margin-bottom: 20px;
        }

        .video-container {
            position: relative;
            width: 100%;
            max-width: 480px; /* Max width of the video */
            aspect-ratio: 480 / 360; /* Maintain 4:3 aspect ratio */
            margin: 10px auto; /* Centering and some margin */
            border: 2px solid #ced4da;
            border-radius: 8px;
            overflow: hidden;
            background-color: #f0f0f0; /* Fallback background */
        }

        .video-container:before {
            content: "Camera preview area";
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            color: #6c757d;
            font-size: 16px;
            pointer-events: none;
            display: block;
            z-index: 0;
            text-align: center;
        }

        video, canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border-radius: 6px; /* Match container's rounding slightly */
        }
        
        #recognitionLiveStatus {
            text-align: center;
            font-weight: bold;
            margin-top: 10px;
            padding: 8px;
            background-color: #f8f9fa;
            border-radius: 4px;
            min-height: 1.5em; /* Prevent layout shift */
        }

        #registeredFaces {
            display: flex;
            flex-wrap: wrap;
            gap: 10px; /* Spacing between face items */
            justify-content: center; /* Center items if they don't fill the row */
        }

        .face-item {
            display: flex;
            flex-direction: column;
            align-items: center;
            margin: 5px; /* Reduced margin as gap is used */
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 8px;
            text-align: center;
            background: #f8f9fa;
            box-shadow: 0 1px 3px rgba(0,0,0,0.05);
            transition: transform 0.2s, box-shadow 0.2s;
            width: 120px; /* Fixed width for consistency */
        }

        .face-item:hover {
            transform: translateY(-3px);
            box-shadow: 0 3px 6px rgba(0,0,0,0.1);
        }

        .face-item img {
            border-radius: 50%;
            margin-bottom: 8px;
            object-fit: cover;
            width: 80px; /* Slightly smaller for the item width */
            height: 80px;
        }
        .face-item p {
            font-size: 0.9em;
            margin-bottom: 5px;
            word-break: break-all;
        }

        button {
            padding: 10px 15px;
            margin: 5px;
            border: none;
            border-radius: 5px;
            background: #0d6efd;
            color: white;
            cursor: pointer;
            transition: background-color 0.2s ease-in-out;
            font-size: 0.95em;
        }

        button:hover {
            background: #0b5ed7;
        }
        
        button:disabled {
            background: #6c757d;
            cursor: not-allowed;
        }

        input[type="text"], input[type="file"] {
            margin: 5px;
            padding: 10px;
            border: 1px solid #ced4da;
            border-radius: 5px;
            width: calc(100% - 22px); /* Full width minus padding and border */
            box-sizing: border-box;
        }
        
        input[type="file"] {
            padding: 5px; /* Less padding for file input */
        }
        
        h3 {
            color: #2c3e50;
            margin-top: 0;
            margin-bottom: 15px;
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
        }
        
        .registration div, .snap-section div {
            margin-bottom:10px;
            display: flex;
            flex-direction: column;
        }
        .registration label, .snap-section label {
            margin-bottom: 5px;
            font-weight: bold;
        }

        .registration input[type="text"],
        .registration input[type="file"],
        .registration button,
        #snapBtn {
            width: 100%;
            box-sizing: border-box;
        }
         #snapAndRegisterBtn {
            background-color: #28a745; /* Green for snap */
        }
        #snapAndRegisterBtn:hover {
            background-color: #218838;
        }


        @media (max-width: 768px) {
            .main-content {
                flex-direction: column;
            }
            .left-column, .right-column {
                min-width: 100%; /* Full width on mobile */
            }
            .video-container {
                max-width: 100%; /* Allow video to take full width of its column */
            }
            h1 {
                font-size: 1.8em;
            }
            button, input {
                font-size: 1em; /* Ensure readability on mobile */
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Local Face Recognition System ðŸ“¸</h1>
        
        <div class="status">
            <p id="modelStatus">Loading models... please wait</p>
        </div>
        
        <div class="camera-status">
            <button id="retryCameraBtn" onclick="initializeCamera()" style="display:none;">Retry Camera</button>
            <p id="cameraStatus"></p>
        </div>
        
        <div class="main-content">
            <div class="left-column">
                <div class="registration">
                    <h3>Register New Face</h3>
                    <div>
                        <label for="personName">Person's Name:</label>
                        <input type="text" id="personName" placeholder="Enter name here">
                    </div>
                    <div>
                        <label for="imageUpload">Upload Image:</label>
                        <input type="file" id="imageUpload" accept="image/*">
                        <button id="registerBtnFile" disabled onclick="handleFileUploadAndRegister()">Register from File</button>
                    </div>
                    <hr>
                     <div>
                        <label>Or Snap Photo from Camera:</label>
                        <button id="snapAndRegisterBtn" disabled onclick="snapPhotoAndRegister()">Snap Photo & Register</button>
                    </div>
                </div>

                <div class="known-faces">
                    <h3>Registered Faces</h3>
                    <div id="registeredFaces"></div>
                </div>
            </div>
            
            <div class="right-column">
                <div class="recognition">
                    <h3>Live Recognition</h3>
                    <div class="video-container">
                        <video id="video" width="480" height="360" autoplay muted playsinline></video>
                        <canvas id="canvas"></canvas> </div>
                    <p id="recognitionLiveStatus">Status: Initializing...</p>
                </div>
            </div>
        </div>
    </div>

    <script>
        let knownFaces = {};
        let modelsLoaded = false;
        let videoStreamActive = false;

        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const modelStatusEl = document.getElementById('modelStatus');
        const cameraStatusEl = document.getElementById('cameraStatus');
        const retryCameraBtn = document.getElementById('retryCameraBtn');
        const registerBtnFile = document.getElementById('registerBtnFile');
        const snapAndRegisterBtn = document.getElementById('snapAndRegisterBtn');
        const imageUploadInput = document.getElementById('imageUpload');
        const personNameInput = document.getElementById('personName');
        const registeredFacesContainer = document.getElementById('registeredFaces');
        const recognitionLiveStatusEl = document.getElementById('recognitionLiveStatus');


        async function loadModels() {
            try {
                modelStatusEl.textContent = 'Loading face detection models...';
                await faceapi.nets.ssdMobilenetv1.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models');
                await faceapi.nets.faceLandmark68Net.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models');
                await faceapi.nets.faceRecognitionNet.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models');
                
                modelStatusEl.textContent = 'Models loaded successfully! âœ…';
                modelsLoaded = true;
                updateButtonStates();
                await loadSavedFaces();
                return true;
            } catch (error) {
                console.error('Error loading models:', error);
                modelStatusEl.textContent = 'Error loading models: ' + error.message;
                retryCameraBtn.style.display = 'inline-block';
                return false;
            }
        }

        async function loadSavedFaces() {
            const saved = localStorage.getItem('knownFaces');
            if (saved) {
                const parsedFaces = JSON.parse(saved);
                // Reconstruct Float32Array descriptors
                for (const name in parsedFaces) {
                    if (parsedFaces[name].descriptor) {
                        parsedFaces[name].descriptor = new Float32Array(Object.values(parsedFaces[name].descriptor));
                    }
                }
                knownFaces = parsedFaces;
                await displayRegisteredFaces();
            }
        }
        
        function updateButtonStates() {
            registerBtnFile.disabled = !modelsLoaded;
            snapAndRegisterBtn.disabled = !(modelsLoaded && videoStreamActive);
        }

        async function handleFileUploadAndRegister() {
            if (!modelsLoaded) {
                alert('Please wait for models to load.');
                return;
            }
            
            const imageFile = imageUploadInput.files[0];
            const personName = personNameInput.value.trim();

            if (!imageFile || !personName) {
                alert('Please select an image file and enter a name.');
                return;
            }

            try {
                const base64Image = await convertFileToBase64(imageFile);
                await processAndRegisterFace(base64Image, personName);
                imageUploadInput.value = ''; // Clear file input
                // personNameInput.value = ''; // Optionally clear name input
            } catch (error) {
                console.error('Error processing uploaded file:', error);
                alert('Error processing image: ' + error.message);
            }
        }

        async function snapPhotoAndRegister() {
            if (!modelsLoaded || !videoStreamActive) {
                alert('Models not loaded or camera not active.');
                return;
            }
            const personName = personNameInput.value.trim();
            if (!personName) {
                alert('Please enter a name for the person.');
                personNameInput.focus();
                return;
            }

            const tempCanvas = document.createElement('canvas');
            tempCanvas.width = video.videoWidth;
            tempCanvas.height = video.videoHeight;
            const ctx = tempCanvas.getContext('2d');
            ctx.drawImage(video, 0, 0, tempCanvas.width, tempCanvas.height);
            
            const base64Image = tempCanvas.toDataURL('image/jpeg');
            
            await processAndRegisterFace(base64Image, personName);
            // personNameInput.value = ''; // Optionally clear name input
        }


        async function processAndRegisterFace(base64Image, personName) {
            modelStatusEl.textContent = `Registering ${personName}...`;
            try {
                const img = await createImageFromBase64(base64Image);
                
                const detection = await faceapi.detectSingleFace(img)
                    .withFaceLandmarks()
                    .withFaceDescriptor();

                if (detection) {
                    knownFaces[personName] = {
                        name: personName,
                        descriptor: Array.from(detection.descriptor), // Store as plain array for JSON
                        image: base64Image 
                    };

                    localStorage.setItem('knownFaces', JSON.stringify(knownFaces));
                    await displayRegisteredFaces(); // Re-render
                    modelStatusEl.textContent = `${personName} registered successfully! ðŸŽ‰`;
                    alert(`${personName} registered successfully!`);
                } else {
                    modelStatusEl.textContent = 'Registration failed: No face detected.';
                    alert('No face detected in the image. Please try a clearer photo or a different angle.');
                }
            } catch (error) {
                console.error('Error registering face:', error);
                modelStatusEl.textContent = 'Error registering face: ' + error.message;
                alert('Error processing image for registration: ' + error.message);
            }
        }


        function convertFileToBase64(file) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onload = () => resolve(reader.result);
                reader.onerror = reject;
                reader.readAsDataURL(file);
            });
        }
        
        function createImageFromBase64(base64Image) {
            return new Promise((resolve, reject) => {
                const img = new Image();
                img.onload = () => resolve(img);
                img.onerror = reject;
                img.src = base64Image;
            });
        }

        async function displayRegisteredFaces() {
            registeredFacesContainer.innerHTML = '';
            if (Object.keys(knownFaces).length === 0) {
                registeredFacesContainer.innerHTML = '<p>No faces registered yet.</p>';
                return;
            }

            for (const name in knownFaces) {
                const data = knownFaces[name];
                const div = document.createElement('div');
                div.className = 'face-item';
                
                div.innerHTML = `
                    <img src="${data.image}" alt="${name}" width="80" height="80">
                    <p>${name}</p>
                    <button onclick="deleteFace('${name}')">Delete</button>
                `;
                registeredFacesContainer.appendChild(div);
            }
        }

        function deleteFace(name) {
            if (confirm(`Are you sure you want to delete ${name}?`)) {
                delete knownFaces[name];
                localStorage.setItem('knownFaces', JSON.stringify(knownFaces));
                displayRegisteredFaces();
                modelStatusEl.textContent = `${name} deleted.`;
            }
        }

        async function initializeCamera() {
            cameraStatusEl.textContent = "Requesting camera access...";
            retryCameraBtn.style.display = 'none';
            
            try {
                if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                    throw new Error("Browser doesn't support mediaDevices API.");
                }
                
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { facingMode: 'user' }, // Prefer front camera
                    audio: false
                });
                
                video.srcObject = stream;
                video.onloadedmetadata = () => {
                    video.play();
                    videoStreamActive = true;
                    cameraStatusEl.textContent = "Camera connected! ðŸŽ¥";
                    modelStatusEl.textContent = modelsLoaded ? "Models loaded. System ready." : "Camera active, models still loading...";
                    video.style.border = "2px solid green"; // Visual feedback
                    
                    // Set canvas dimensions once video metadata is loaded
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    
                    updateButtonStates();
                    if (modelsLoaded) {
                        startFaceDetection();
                    }
                };
                
            } catch (err) {
                console.error("Error accessing webcam:", err);
                cameraStatusEl.textContent = "Camera error: " + err.message;
                videoStreamActive = false;
                updateButtonStates();
                retryCameraBtn.style.display = 'inline-block';
                
                if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') {
                    alert("Camera access was denied. Please check browser permissions.");
                } else if (err.name === 'NotFoundError' || err.name === 'DevicesNotFoundError') {
                    alert("No camera detected. Please connect a camera.");
                } else {
                    alert("Cannot access webcam: " + err.message);
                }
            }
        }
        
        let detectionInterval;
        async function startFaceDetection() {
            if (!modelsLoaded || !videoStreamActive) return;
            
            recognitionLiveStatusEl.textContent = "Starting live detection...";
            
            // Prepare LabeledFaceDescriptors
            const labeledFaceDescriptors = await Promise.all(
                Object.values(knownFaces).map(async (face) => {
                    if (face.descriptor && face.descriptor.length > 0) {
                         // Ensure descriptor is Float32Array
                        const descriptorArray = (face.descriptor instanceof Float32Array) 
                                              ? face.descriptor 
                                              : new Float32Array(Object.values(face.descriptor));
                        return new faceapi.LabeledFaceDescriptors(face.name, [descriptorArray]);
                    }
                    return null;
                })
            ).then(descriptors => descriptors.filter(d => d !== null));


            let faceMatcher;
            if (labeledFaceDescriptors.length > 0) {
                faceMatcher = new faceapi.FaceMatcher(labeledFaceDescriptors, 0.55); // Adjusted threshold
                recognitionLiveStatusEl.textContent = "Matcher created. Detecting...";
            } else {
                recognitionLiveStatusEl.textContent = "No registered faces to match. Detecting all faces...";
            }

            const displaySize = { width: video.videoWidth, height: video.videoHeight };
            faceapi.matchDimensions(canvas, displaySize); // Match canvas element size to video feed size

            if (detectionInterval) clearInterval(detectionInterval);

            detectionInterval = setInterval(async () => {
                if (video.paused || video.ended || !videoStreamActive) {
                    recognitionLiveStatusEl.textContent = "Detection paused (video not active).";
                    return;
                }
                 if (video.readyState < HTMLMediaElement.HAVE_CURRENT_DATA) { // wait for video frame to be available
                    return;
                }

                const detections = await faceapi.detectAllFaces(video, new faceapi.SsdMobilenetv1Options({ minConfidence: 0.5 }))
                    .withFaceLandmarks()
                    .withFaceDescriptors();
                
                const ctx = canvas.getContext('2d');
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                
                if (detections && detections.length > 0) {
                    const resizedDetections = faceapi.resizeResults(detections, displaySize);
                    
                    resizedDetections.forEach(detection => {
                        const box = detection.detection.box;
                        let label = "Unknown";
                        let color = 'red';

                        if (faceMatcher) {
                            const bestMatch = faceMatcher.findBestMatch(detection.descriptor);
                            if (bestMatch.label !== 'unknown') {
                                label = `${bestMatch.label} (${bestMatch.distance.toFixed(2)})`;
                                color = 'green';
                            } else {
                                label = `Unknown (${bestMatch.distance.toFixed(2)})`;
                            }
                        }
                         recognitionLiveStatusEl.textContent = `Detected: ${label}`;
                        const drawBox = new faceapi.draw.DrawBox(box, { 
                            label: label, 
                            lineWidth: 2,
                            boxColor: color
                        });
                        drawBox.draw(canvas);
                    });
                } else {
                    recognitionLiveStatusEl.textContent = "No face detected in view.";
                }
            }, 200); // Detection frequency
        }


        window.addEventListener('DOMContentLoaded', async () => {
            if (typeof faceapi === 'undefined') {
                modelStatusEl.textContent = 'Error: face-api.js not loaded. Please check your internet connection.';
                cameraStatusEl.textContent = 'Cannot start system.';
                retryCameraBtn.style.display = 'none'; // No point retrying camera if core lib failed
                return;
            }
            
            const modelsLoadedSuccess = await loadModels();
            if (modelsLoadedSuccess) {
                await initializeCamera(); // This will call startFaceDetection if successful
            } else {
                // Error messages handled within loadModels
                retryCameraBtn.style.display = 'inline-block'; // Allow retry for model loading
                retryCameraBtn.onclick = async () => { // Make retry button reload models then camera
                    retryCameraBtn.style.display = 'none';
                    const reloaded = await loadModels();
                    if(reloaded) await initializeCamera();
                    else retryCameraBtn.style.display = 'inline-block';
                };
            }
            updateButtonStates();
        });

        // Stop stream when page is closed or navigated away
        window.addEventListener('beforeunload', () => {
            if (video && video.srcObject) {
                video.srcObject.getTracks().forEach(track => track.stop());
            }
            if (detectionInterval) {
                clearInterval(detectionInterval);
            }
        });

    </script>
</body>
</html>
