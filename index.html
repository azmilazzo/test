<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0" />
  <title>Face Recognition Web App</title>
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
  <style>
    body {
      margin: 0;
      font-family: sans-serif;
      background: #f9f9f9;
      padding: 1rem;
    }

    .container {
      display: flex;
      flex-direction: column;
      gap: 1rem;
    }

    .video-wrapper {
      position: relative;
      width: 100%;
    }

    video, canvas {
      width: 100%;
      border-radius: 8px;
    }

    canvas {
      position: absolute;
      top: 0;
      left: 0;
      z-index: 10;
    }

    input, button {
      width: 100%;
      padding: 10px;
      font-size: 16px;
      border: 1px solid #ccc;
      border-radius: 5px;
    }

    .face-list {
      margin-top: 10px;
    }

    .face-item {
      display: flex;
      align-items: center;
      gap: 10px;
      margin-bottom: 10px;
    }

    .face-item img {
      width: 50px;
      height: 50px;
      border-radius: 50%;
      object-fit: cover;
    }
  </style>
</head>
<body>
  <h2>Face Recognition</h2>
  <div class="container">
    <div class="video-wrapper">
      <video id="video" autoplay muted playsinline></video>
      <canvas id="overlay"></canvas>
    </div>

    <input type="file" id="imageUpload" accept="image/*" />
    <input type="text" id="nameInput" placeholder="Enter name" />
    <button onclick="registerFace()">Register Face</button>
    <button onclick="capturePhoto()">Capture from Camera</button>

    <div class="face-list" id="faceList"></div>
  </div>

  <canvas id="snapshotCanvas" style="display:none;"></canvas>

  <script>
    const labeledDescriptors = [];
    let faceMatcher = null;

    const video = document.getElementById('video');
    const canvas = document.getElementById('overlay');

    // Start camera immediately
    navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' } })
      .then(stream => {
        video.srcObject = stream;
        video.onloadedmetadata = () => {
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
        };
      })
      .catch(err => {
        alert("Error accessing camera: " + err.message);
        console.error(err);
      });

    video.addEventListener('play', () => {
      const displaySize = { width: video.videoWidth, height: video.videoHeight };
      setInterval(async () => {
        if (!faceMatcher) return;

        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
          .withFaceLandmarks().withFaceDescriptors();

        const resized = faceapi.resizeResults(detections, displaySize);
        canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);

        resized.forEach(d => {
          const best = faceMatcher.findBestMatch(d.descriptor);
          new faceapi.draw.DrawBox(d.detection.box, { label: best.toString() }).draw(canvas);
        });
      }, 300);
    });

    async function loadModels() {
      await faceapi.nets.tinyFaceDetector.loadFromUri('models');
      await faceapi.nets.faceLandmark68Net.loadFromUri('models');
      await faceapi.nets.faceRecognitionNet.loadFromUri('models');
    }

    async function registerFace() {
      const file = document.getElementById('imageUpload').files[0];
      const name = document.getElementById('nameInput').value.trim();
      if (!file || !name) return alert("Choose image and enter name.");

      const img = await faceapi.bufferToImage(file);
      const detection = await faceapi.detectSingleFace(img, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks().withFaceDescriptor();
      if (!detection) return alert("No face detected.");

      labeledDescriptors.push(new faceapi.LabeledFaceDescriptors(name, [detection.descriptor]));
      faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, 0.6);
      showFace(name, file);
    }

    function showFace(name, file) {
      const reader = new FileReader();
      reader.onload = () => {
        const item = document.createElement('div');
        item.className = 'face-item';
        item.innerHTML = `<img src="${reader.result}"><span>${name}</span>`;
        document.getElementById('faceList').appendChild(item);
      };
      reader.readAsDataURL(file);
    }

    function capturePhoto() {
      const canvas = document.getElementById('snapshotCanvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      const ctx = canvas.getContext('2d');
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      canvas.toBlob(blob => {
        const file = new File([blob], "snapshot.png", { type: "image/png" });
        const data = new DataTransfer();
        data.items.add(file);
        document.getElementById('imageUpload').files = data.files;
        alert("Snapshot captured! Enter a name and register.");
      });
    }

    loadModels();
  </script>
</body>
</html>
