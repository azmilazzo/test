<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Mobile Face Recognition</title>
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 10px;
    }

    .main-content {
      display: flex;
      flex-wrap: wrap;
      gap: 20px;
    }

    .left-column, .right-column {
      flex: 1;
      min-width: 300px;
    }

    video, canvas {
      width: 100%;
      height: auto;
      border: 1px solid #ccc;
      border-radius: 10px;
    }

    .face-item {
      display: flex;
      align-items: center;
      gap: 10px;
      margin-top: 10px;
      flex-wrap: wrap;
    }

    .face-item img {
      width: 50px;
      height: 50px;
      object-fit: cover;
      border-radius: 50%;
    }

    input, button {
      margin-top: 10px;
      padding: 8px;
      width: 100%;
      box-sizing: border-box;
      font-size: 16px;
    }

    #videoPreview {
      display: none;
    }

    @media (max-width: 768px) {
      input, button {
        width: 100%;
      }
    }
  </style>
</head>
<body>
  <h2>Mobile Face Recognition App</h2>
  <div class="main-content">
    <div class="left-column">
      <video id="video" autoplay muted playsinline></video>
      <canvas id="overlay" style="position:absolute; top:0; left:0;"></canvas>
      <canvas id="snapshotCanvas" style="display:none;"></canvas>

      <input type="file" id="imageUpload" accept="image/*">
      <input type="text" id="nameInput" placeholder="Enter name to register">
      <button onclick="registerFace()">Register Face</button>
      <button onclick="capturePhoto()">Capture from Camera</button>
    </div>

    <div class="right-column">
      <h3>Registered Faces</h3>
      <div id="faceList"></div>
    </div>
  </div>

  <script>
    const labeledDescriptors = [];
    let faceMatcher;
    let displaySize;

    async function loadModels() {
      await faceapi.nets.tinyFaceDetector.loadFromUri('/models');
      await faceapi.nets.faceRecognitionNet.loadFromUri('/models');
      await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
      startVideo();
    }

    function startVideo() {
      const video = document.getElementById('video');
      navigator.mediaDevices.getUserMedia({ video: {} })
        .then(stream => {
          video.srcObject = stream;
        })
        .catch(err => console.error("Camera error:", err));
    }

    document.getElementById('video').addEventListener('play', () => {
      const canvas = document.getElementById('overlay');
      faceapi.matchDimensions(canvas, document.getElementById('video'));
      displaySize = {
        width: document.getElementById('video').videoWidth,
        height: document.getElementById('video').videoHeight
      };
      setInterval(detectFaces, 100);
    });

    async function detectFaces() {
      const video = document.getElementById('video');
      const canvas = document.getElementById('overlay');
      const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptors();

      const resizedDetections = faceapi.resizeResults(detections, displaySize);
      canvas.width = displaySize.width;
      canvas.height = displaySize.height;

      const ctx = canvas.getContext('2d');
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      if (faceMatcher) {
        resizedDetections.forEach(detection => {
          const bestMatch = faceMatcher.findBestMatch(detection.descriptor);
          const label = bestMatch.label === 'unknown' ? 'Unknown' : bestMatch.label;
          const box = detection.detection.box;
          const drawBox = new faceapi.draw.DrawBox(box, {
            label,
            lineWidth: 2,
            boxColor: bestMatch.distance < 0.6 ? 'green' : 'red'
          });
          drawBox.draw(canvas);
        });
      }
    }

    async function registerFace() {
      const input = document.getElementById('imageUpload');
      const name = document.getElementById('nameInput').value.trim();

      if (!input.files.length || !name) {
        alert("Please select a photo and enter a name.");
        return;
      }

      const imgFile = input.files[0];
      const img = await faceapi.bufferToImage(imgFile);
      const detection = await faceapi.detectSingleFace(img, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptor();

      if (!detection) {
        alert("No face detected.");
        return;
      }

      labeledDescriptors.push(new faceapi.LabeledFaceDescriptors(name, [detection.descriptor]));
      faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, 0.6);
      addFaceToList(name, imgFile);
      input.value = '';
      document.getElementById('nameInput').value = '';
    }

    function addFaceToList(name, file) {
      const reader = new FileReader();
      reader.onload = () => {
        const faceItem = document.createElement('div');
        faceItem.className = 'face-item';
        faceItem.innerHTML = `<img src="${reader.result}" alt="${name}"><span>${name}</span>`;
        document.getElementById('faceList').appendChild(faceItem);
      };
      reader.readAsDataURL(file);
    }

    function capturePhoto() {
      const video = document.getElementById('video');
      const canvas = document.getElementById('snapshotCanvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      const ctx = canvas.getContext('2d');
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      canvas.toBlob(blob => {
        const file = new File([blob], 'snapshot.png', { type: 'image/png' });
        const dataTransfer = new DataTransfer();
        dataTransfer.items.add(file);
        document.getElementById('imageUpload').files = dataTransfer.files;
        alert("Photo captured. Now enter name and click Register Face.");
      });
    }

    loadModels();
  </script>
</body>
</html>
