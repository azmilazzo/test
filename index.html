<!DOCTYPE html>
<html>
<head>
    <title>Local Face Recognition System</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #f8f9fa;
            color: #333;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 15px;
        }
        
        h1 {
            text-align: center;
            margin-bottom: 25px;
            color: #2c3e50;
        }

        .status, .camera-status {
            text-align: center;
            margin-bottom: 15px;
            padding: 10px;
            background-color: #e9ecef;
            border-radius: 8px;
            font-size: 0.9em;
        }
        
        #retryCameraBtn {
            background-color: #007bff;
            color: white;
            padding: 8px 15px;
        }
        
        #retryCameraBtn:hover {
            background-color: #0056b3;
        }
        
        .main-content {
            display: flex;
            flex-direction: row;
            flex-wrap: wrap; /* Allow columns to wrap */
            gap: 20px;
        }

        .left-column, .right-column {
            flex: 1;
            min-width: 300px; /* Minimum width before stacking */
            background: #fff;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        
        .registration, .known-faces, .recognition {
            margin-bottom: 20px;
        }

        .video-container {
            position: relative;
            width: 100%;
            max-width: 480px; /* Max width of the video */
            aspect-ratio: 480 / 360; /* Maintain 4:3 aspect ratio */
            margin: 10px auto; /* Centering and some margin */
            border: 2px solid #ced4da;
            border-radius: 8px;
            overflow: hidden;
            background-color: #f0f0f0; /* Fallback background */
        }

        .video-container:before {
            content: "Camera preview area";
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            color: #6c757d;
            font-size: 16px;
            pointer-events: none;
            display: block;
            z-index: 0;
            text-align: center;
        }

        video, canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border-radius: 6px; /* Match container's rounding slightly */
        }
        
        #recognitionLiveStatus {
            text-align: center;
            font-weight: bold;
            margin-top: 10px;
            padding: 8px;
            background-color: #f8f9fa;
            border-radius: 4px;
            min-height: 1.5em; /* Prevent layout shift */
        }

        #registeredFaces {
            display: flex;
            flex-direction: column; /* Stack groups vertically */
            gap: 15px; /* Space between groups */
        }

        .face-group {
            margin-bottom: 20px;
            padding: 10px;
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            background-color: #fcfcfc;
        }

        .face-group h4 {
            text-align: center;
            margin-top: 0;
            margin-bottom: 15px;
            color: #2c3e50;
            font-size: 1.1em;
            border-bottom: 1px dotted #ccc; 
            padding-bottom: 5px;
        }

        .face-items-container {
            display: flex;
            flex-wrap: wrap;
            gap: 10px; /* Spacing between face items */
            justify-content: center; /* Center items if they don't fill the row */
        }

        .face-item {
            display: flex;
            flex-direction: column;
            align-items: center;
            margin: 5px; /* Reduced margin as gap is used */
            padding: 8px; /* Slightly reduced padding */
            border: 1px solid #ddd;
            border-radius: 8px;
            text-align: center;
            background: #f8f9fa;
            box-shadow: 0 1px 3px rgba(0,0,0,0.08); /* Slightly softer shadow */
            transition: transform 0.2s, box-shadow 0.2s;
            width: 100px; /* Adjusted width for consistency within groups */
        }

        .face-item:hover {
            transform: translateY(-3px);
            box-shadow: 0 3px 6px rgba(0,0,0,0.1);
        }

        .face-item img {
            border-radius: 50%;
            margin-bottom: 8px;
            object-fit: cover;
            width: 70px; /* Adjusted size within the group */
            height: 70px;
        }
        .face-item p { /* Hidden as name is in group header */
            display: none; 
        }

        button {
            padding: 10px 15px;
            margin: 5px;
            border: none;
            border-radius: 5px;
            background: #0d6efd;
            color: white;
            cursor: pointer;
            transition: background-color 0.2s ease-in-out;
            font-size: 0.95em;
        }

        button:hover {
            background: #0b5ed7;
        }
        
        button:disabled {
            background: #6c757d;
            cursor: not-allowed;
        }

        /* Specific delete button styling within face-item */
        .face-item button {
            margin-top: 5px;
            padding: 6px 10px;
            font-size: 0.8em;
            background-color: #dc3545; /* Red for delete */
        }

        .face-item button:hover {
            background-color: #c82333;
        }


        input[type="text"], input[type="file"] {
            margin: 5px;
            padding: 10px;
            border: 1px solid #ced4da;
            border-radius: 5px;
            width: calc(100% - 22px); /* Full width minus padding and border */
            box-sizing: border-box;
        }
        
        input[type="file"] {
            padding: 5px; /* Less padding for file input */
        }
        
        h3 {
            color: #2c3e50;
            margin-top: 0;
            margin-bottom: 15px;
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
        }
        
        .registration div, .snap-section div {
            margin-bottom:10px;
            display: flex;
            flex-direction: column;
        }
        .registration label, .snap-section label {
            margin-bottom: 5px;
            font-weight: bold;
        }

        .registration input[type="text"],
        .registration input[type="file"],
        .registration button,
        #snapBtn {
            width: 100%;
            box-sizing: border-box;
        }
         #snapAndRegisterBtn {
            background-color: #28a745; /* Green for snap */
        }
        #snapAndRegisterBtn:hover {
            background-color: #218838;
        }


        @media (max-width: 768px) {
            .main-content {
                flex-direction: column;
            }
            .left-column, .right-column {
                min-width: 100%; /* Full width on mobile */
            }
            .video-container {
                max-width: 100%; /* Allow video to take full width of its column */
            }
            h1 {
                font-size: 1.8em;
            }
            button, input {
                font-size: 1em; /* Ensure readability on mobile */
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Local Face Recognition System ðŸ“¸</h1>
        
        <div class="status">
            <p id="modelStatus">Loading models... please wait</p>
        </div>
        
        <div class="camera-status">
            <button id="retryCameraBtn" onclick="initializeCamera()" style="display:none;">Retry Camera</button>
            <p id="cameraStatus"></p>
        </div>
        
        <div class="main-content">
            <div class="left-column">
                <div class="registration">
                    <h3>Register New Face</h3>
                    <div>
                        <label for="personName">Person's Name:</label>
                        <input type="text" id="personName" placeholder="Enter name here">
                    </div>
                    <div>
                        <label for="imageUpload">Upload Image:</label>
                        <input type="file" id="imageUpload" accept="image/*">
                        <button id="registerBtnFile" disabled onclick="handleFileUploadAndRegister()">Register from File</button>
                    </div>
                    <hr>
                     <div>
                        <label>Or Snap Photo from Camera:</label>
                        <button id="snapAndRegisterBtn" disabled onclick="snapPhotoAndRegister()">Snap Photo & Register</button>
                    </div>
                </div>

                <div class="known-faces">
                    <h3>Registered Faces</h3>
                    <div id="registeredFaces"></div>
                </div>
            </div>
            
            <div class="right-column">
                <div class="recognition">
                    <h3>Live Recognition</h3>
                    <div class="video-container">
                        <video id="video" width="480" height="360" autoplay muted playsinline></video>
                        <canvas id="canvas"></canvas> </div>
                    <p id="recognitionLiveStatus">Status: Initializing...</p>
                </div>
            </div>
        </div>
    </div>

    <script>
        let knownFaces = []; // Changed to an array

        let modelsLoaded = false;
        let videoStreamActive = false;

        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const modelStatusEl = document.getElementById('modelStatus');
        const cameraStatusEl = document.getElementById('cameraStatus');
        const retryCameraBtn = document.getElementById('retryCameraBtn');
        const registerBtnFile = document.getElementById('registerBtnFile');
        const snapAndRegisterBtn = document.getElementById('snapAndRegisterBtn');
        const imageUploadInput = document.getElementById('imageUpload');
        const personNameInput = document.getElementById('personName');
        const registeredFacesContainer = document.getElementById('registeredFaces');
        const recognitionLiveStatusEl = document.getElementById('recognitionLiveStatus');


        async function loadModels() {
            try {
                modelStatusEl.textContent = 'Loading face detection models...';
                await faceapi.nets.ssdMobilenetv1.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models');
                await faceapi.nets.faceLandmark68Net.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models');
                await faceapi.nets.faceRecognitionNet.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models');
                
                modelStatusEl.textContent = 'Models loaded successfully! âœ…';
                modelsLoaded = true;
                updateButtonStates();
                await loadSavedFaces();
                return true;
            } catch (error) {
                console.error('Error loading models:', error);
                modelStatusEl.textContent = 'Error loading models: ' + error.message;
                retryCameraBtn.style.display = 'inline-block';
                return false;
            }
        }

        async function loadSavedFaces() {
            const saved = localStorage.getItem('knownFaces');
            if (saved) {
                let parsedFaces = JSON.parse(saved);

                // Migration logic: Check if parsedFaces is an object (old format)
                if (!Array.isArray(parsedFaces)) {
                    console.warn("Migrating old knownFaces data from object to array format.");
                    const oldFaces = parsedFaces; // Store the old object
                    parsedFaces = []; // Initialize as an empty array for new format

                    for (const name in oldFaces) {
                        if (oldFaces.hasOwnProperty(name) && oldFaces[name].descriptor) {
                            // Create a unique ID for existing faces during migration
                            const uniqueId = `${name}_${Date.now()}`; 
                            parsedFaces.push({
                                id: uniqueId,
                                name: oldFaces[name].name,
                                descriptor: new Float32Array(Object.values(oldFaces[name].descriptor)),
                                image: oldFaces[name].image
                            });
                        }
                    }
                    // Overwrite the localStorage with the new array format
                    localStorage.setItem('knownFaces', JSON.stringify(parsedFaces));
                }

                // Now parsedFaces is guaranteed to be an array
                knownFaces = parsedFaces.map(face => {
                    if (face.descriptor) {
                        face.descriptor = new Float32Array(Object.values(face.descriptor));
                    }
                    return face;
                });
                await displayRegisteredFaces();
            }
        }
        
        function updateButtonStates() {
            registerBtnFile.disabled = !modelsLoaded;
            snapAndRegisterBtn.disabled = !(modelsLoaded && videoStreamActive);
        }

        async function handleFileUploadAndRegister() {
            if (!modelsLoaded) {
                alert('Please wait for models to load.');
                return;
            }
            
            const imageFile = imageUploadInput.files[0];
            const personName = personNameInput.value.trim();

            if (!imageFile || !personName) {
                alert('Please select an image file and enter a name.');
                return;
            }

            try {
                const base64Image = await convertFileToBase64(imageFile);
                await processAndRegisterFace(base64Image, personName);
                imageUploadInput.value = ''; // Clear file input
                // personNameInput.value = ''; // Optionally clear name input
            } catch (error) {
                console.error('Error processing uploaded file:', error);
                alert('Error processing image: ' + error.message);
            }
        }

        async function snapPhotoAndRegister() {
            if (!modelsLoaded || !videoStreamActive) {
                alert('Models not loaded or camera not active.');
                return;
            }
            const personName = personNameInput.value.trim();
            if (!personName) {
                alert('Please enter a name for the person.');
                personNameInput.focus();
                return;
            }

            const tempCanvas = document.createElement('canvas');
            tempCanvas.width = video.videoWidth;
            tempCanvas.height = video.videoHeight;
            const ctx = tempCanvas.getContext('2d');
            ctx.drawImage(video, 0, 0, tempCanvas.width, tempCanvas.height);
            
            const base64Image = tempCanvas.toDataURL('image/jpeg');
            
            await processAndRegisterFace(base64Image, personName);
            // personNameInput.value = ''; // Optionally clear name input
        }


        async function processAndRegisterFace(base64Image, personName) {
            modelStatusEl.textContent = `Registering ${personName}...`;
            try {
                const img = await createImageFromBase64(base64Image);
                
                const detection = await faceapi.detectSingleFace(img)
                    .withFaceLandmarks()
                    .withFaceDescriptor();

                if (detection) {
                    // Generate a unique ID for each registered face
                    const uniqueId = `${personName}_${Date.now()}`; 
                    knownFaces.push({ // Push to the array
                        id: uniqueId,
                        name: personName,
                        descriptor: Array.from(detection.descriptor), // Store as plain array for JSON
                        image: base64Image 
                    });

                    localStorage.setItem('knownFaces', JSON.stringify(knownFaces));
                    await displayRegisteredFaces(); // Re-render
                    modelStatusEl.textContent = `${personName} registered successfully! ðŸŽ‰`;
                    alert(`${personName} registered successfully!`);
                } else {
                    modelStatusEl.textContent = 'Registration failed: No face detected.';
                    alert('No face detected in the image. Please try a clearer photo or a different angle.');
                }
            } catch (error) {
                console.error('Error registering face:', error);
                modelStatusEl.textContent = 'Error registering face: ' + error.message;
                alert('Error processing image for registration: ' + error.message);
            }
        }


        function convertFileToBase64(file) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onload = () => resolve(reader.result);
                reader.onerror = reject;
                reader.readAsDataURL(file);
            });
        }
        
        function createImageFromBase64(base64Image) {
            return new Promise((resolve, reject) => {
                const img = new Image();
                img.onload = () => resolve(img);
                img.onerror = reject;
                img.src = base64Image;
            });
        }

        async function displayRegisteredFaces() {
            registeredFacesContainer.innerHTML = '';
            if (knownFaces.length === 0) {
                registeredFacesContainer.innerHTML = '<p>No faces registered yet.</p>';
                return;
            }

            // 1. Group faces by name
            const groupedFaces = knownFaces.reduce((acc, face) => {
                if (!acc[face.name]) {
                    acc[face.name] = [];
                }
                acc[face.name].push(face);
                return acc;
            }, {});

            // 2. Sort names alphabetically for consistent display
            const sortedNames = Object.keys(groupedFaces).sort();

            // 3. Render each group
            sortedNames.forEach(name => {
                const groupDiv = document.createElement('div');
                groupDiv.className = 'face-group'; // Add a class for styling

                const groupHeader = document.createElement('h4');
                groupHeader.textContent = name;
                groupDiv.appendChild(groupHeader);

                const groupItemsContainer = document.createElement('div');
                groupItemsContainer.className = 'face-items-container'; // Container for individual face items
                
                groupedFaces[name].forEach(data => {
                    const div = document.createElement('div');
                    div.className = 'face-item';
                    
                    div.innerHTML = `
                        <img src="${data.image}" alt="${data.name}" width="80" height="80">
                        <button onclick="deleteFace('${data.id}')">Delete</button>
                    `;
                    groupItemsContainer.appendChild(div);
                });

                groupDiv.appendChild(groupItemsContainer);
                registeredFacesContainer.appendChild(groupDiv);
            });
        }

        function deleteFace(idToDelete) { // Accept ID instead of name
            const faceToDelete = knownFaces.find(face => face.id === idToDelete);
            if (!faceToDelete) {
                console.warn('Face with ID not found:', idToDelete);
                return; 
            }

            if (confirm(`Are you sure you want to delete ${faceToDelete.name} (this specific image)?`)) {
                knownFaces = knownFaces.filter(face => face.id !== idToDelete); // Filter out the deleted face
                localStorage.setItem('knownFaces', JSON.stringify(knownFaces));
                displayRegisteredFaces();
                modelStatusEl.textContent = `${faceToDelete.name}'s image deleted.`;
            }
        }

        async function initializeCamera() {
            cameraStatusEl.textContent = "Requesting camera access...";
            retryCameraBtn.style.display = 'none';
            
            try {
                if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                    throw new Error("Browser doesn't support mediaDevices API.");
                }
                
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { facingMode: 'user' }, // Prefer front camera
                    audio: false
                });
                
                video.srcObject = stream;
                video.onloadedmetadata = () => {
                    video.play();
                    videoStreamActive = true;
                    cameraStatusEl.textContent = "Camera connected! ðŸŽ¥";
                    modelStatusEl.textContent = modelsLoaded ? "Models loaded. System ready." : "Camera active, models still loading...";
                    video.style.border = "2px solid green"; // Visual feedback
                    
                    // Set canvas dimensions once video metadata is loaded
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    
                    updateButtonStates();
                    if (modelsLoaded) {
                        startFaceDetection();
                    }
                };
                
            } catch (err) {
                console.error("Error accessing webcam:", err);
                cameraStatusEl.textContent = "Camera error: " + err.message;
                videoStreamActive = false;
                updateButtonStates();
                retryCameraBtn.style.display = 'inline-block';
                
                if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') {
                    alert("Camera access was denied. Please check browser permissions.");
                } else if (err.name === 'NotFoundError' || err.name === 'DevicesNotFoundError') {
                    alert("No camera detected. Please connect a camera.");
                } else {
                    alert("Cannot access webcam: " + err.message);
                }
            }
        }
        
        let detectionInterval;
        async function startFaceDetection() {
            if (!modelsLoaded || !videoStreamActive) return;
            
            recognitionLiveStatusEl.textContent = "Starting live detection...";
            
            // Prepare LabeledFaceDescriptors from the array of known faces
            const labeledFaceDescriptors = await Promise.all(
                knownFaces.map(async (face) => { // Iterate through the array
                    if (face.descriptor && face.descriptor.length > 0) {
                         // Ensure descriptor is Float32Array
                        const descriptorArray = (face.descriptor instanceof Float32Array) 
                                              ? face.descriptor 
                                              : new Float32Array(Object.values(face.descriptor));
                        return new faceapi.LabeledFaceDescriptors(face.name, [descriptorArray]);
                    }
                    return null;
                })
            ).then(descriptors => descriptors.filter(d => d !== null));


            let faceMatcher;
            if (labeledFaceDescriptors.length > 0) {
                faceMatcher = new faceapi.FaceMatcher(labeledFaceDescriptors, 0.55); // Adjusted threshold
                recognitionLiveStatusEl.textContent = "Matcher created. Detecting...";
            } else {
                recognitionLiveStatusEl.textContent = "No registered faces to match. Detecting all faces...";
            }

            const displaySize = { width: video.videoWidth, height: video.videoHeight };
            faceapi.matchDimensions(canvas, displaySize); // Match canvas element size to video feed size

            if (detectionInterval) clearInterval(detectionInterval);

            detectionInterval = setInterval(async () => {
                if (video.paused || video.ended || !videoStreamActive) {
                    recognitionLiveStatusEl.textContent = "Detection paused (video not active).";
                    return;
                }
                 if (video.readyState < HTMLMediaElement.HAVE_CURRENT_DATA) { // wait for video frame to be available
                    return;
                }

                const detections = await faceapi.detectAllFaces(video, new faceapi.SsdMobilenetv1Options({ minConfidence: 0.5 }))
                    .withFaceLandmarks()
                    .withFaceDescriptors();
                
                const ctx = canvas.getContext('2d');
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                
                if (detections && detections.length > 0) {
                    const resizedDetections = faceapi.resizeResults(detections, displaySize);
                    
                    resizedDetections.forEach(detection => {
                        const box = detection.detection.box;
                        let label = "Unknown";
                        let color = 'red';

                        if (faceMatcher) {
                            const bestMatch = faceMatcher.findBestMatch(detection.descriptor);
                            // Only update label if a known face is found
                            if (bestMatch.label !== 'unknown') {
                                label = `${bestMatch.label} (${bestMatch.distance.toFixed(2)})`;
                                color = 'green';
                            } else {
                                label = `Unknown (${bestMatch.distance.toFixed(2)})`;
                            }
                        }
                         recognitionLiveStatusEl.textContent = `Detected: ${label}`;
                        const drawBox = new faceapi.draw.DrawBox(box, { 
                            label: label, 
                            lineWidth: 2,
                            boxColor: color
                        });
                        drawBox.draw(canvas);
                    });
                } else {
                    recognitionLiveStatusEl.textContent = "No face detected in view.";
                }
            }, 200); // Detection frequency
        }


        window.addEventListener('DOMContentLoaded', async () => {
            if (typeof faceapi === 'undefined') {
                modelStatusEl.textContent = 'Error: face-api.js not loaded. Please check your internet connection.';
                cameraStatusEl.textContent = 'Cannot start system.';
                retryCameraBtn.style.display = 'none'; // No point retrying camera if core lib failed
                return;
            }
            
            const modelsLoadedSuccess = await loadModels();
            if (modelsLoadedSuccess) {
                await initializeCamera(); // This will call startFaceDetection if successful
            } else {
                // Error messages handled within loadModels
                retryCameraBtn.style.display = 'inline-block'; // Allow retry for model loading
                retryCameraBtn.onclick = async () => { // Make retry button reload models then camera
                    retryCameraBtn.style.display = 'none';
                    const reloaded = await loadModels();
                    if(reloaded) await initializeCamera();
                    else retryCameraBtn.style.display = 'inline-block';
                };
            }
            updateButtonStates();
        });

        // Stop stream when page is closed or navigated away
        window.addEventListener('beforeunload', () => {
            if (video && video.srcObject) {
                video.srcObject.getTracks().forEach(track => track.stop());
            }
            if (detectionInterval) {
                clearInterval(detectionInterval);
            }
        });

    </script>
</body>
</html>
